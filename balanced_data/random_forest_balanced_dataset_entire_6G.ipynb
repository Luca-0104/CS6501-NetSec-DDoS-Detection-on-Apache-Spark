{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a6a711-0598-4138-8276-f33fbc1b2d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/ubuntu/.local/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe96d5c-e3d5-42ea-862d-24321480e476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/ubuntu/.local/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4042371c-2a7b-4314-be69-ab8707693cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/spark-3.3.1-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.3.1-bin-hadoop3')\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72df189-e168-4fba-b560-3618a7a542ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/29 23:05:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# The entry point into all functionality in Spark is the SparkSession class.\n",
    "spark = (SparkSession\n",
    "\t.builder\n",
    "\t.appName(\"DS5110/CS5501: my awesome Spark program - balanced att1\")\n",
    "\t.master(\"spark://172.31.8.146:7077\")\n",
    "\t.config(\"spark.executor.memory\", \"1024M\")\n",
    "\t.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633b8cb1-2f55-4540-b895-78f4cc5bb4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-8-146.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.31.8.146:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DS5110/CS5501: my awesome Spark program - balanced att1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x763618e60880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd6050-67e4-4099-a2e2-210b90151cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d84b41-6e68-4901-bb19-776f56fe8610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd496a-3e70-4a41-beec-3a6e8912091c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e4c1c5-7946-4338-aa39-5cd071e5bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, count, desc, rand, when\n",
    "\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler, PCA\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ba669-f385-4d62-b98b-3573c3479ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c505f47a-3cf0-48e6-ae6a-f695a269f506",
   "metadata": {},
   "source": [
    "## specify the data type of each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6932807c-4cd6-407b-9ac7-16a0d4228b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField('_c0', IntegerType()),\n",
    "    StructField('Flow ID', StringType()),\n",
    "    StructField('Src IP', StringType()),\n",
    "    StructField('Src Port', IntegerType()),\n",
    "    StructField('Dst IP', StringType()),\n",
    "    StructField('Dst Port', IntegerType()),\n",
    "    StructField('Protocol', IntegerType()),\n",
    "    StructField('Timestamp', StringType()),\n",
    "    StructField('Flow Duration', IntegerType()),\n",
    "    StructField('Tot Fwd Pkts', IntegerType()),\n",
    "    StructField('Tot Bwd Pkts', IntegerType()),\n",
    "    StructField('TotLen Fwd Pkts', FloatType()),\n",
    "    StructField('TotLen Bwd Pkts', FloatType()),\n",
    "    StructField('Fwd Pkt Len Max', FloatType()),\n",
    "    StructField('Fwd Pkt Len Min', FloatType()),\n",
    "    StructField('Fwd Pkt Len Mean', FloatType()),\n",
    "    StructField('Fwd Pkt Len Std', FloatType()),\n",
    "    StructField('Bwd Pkt Len Max', FloatType()),\n",
    "    StructField('Bwd Pkt Len Min', FloatType()),\n",
    "    StructField('Bwd Pkt Len Mean', FloatType()),\n",
    "    StructField('Bwd Pkt Len Std', FloatType()),\n",
    "    StructField('Flow Byts/s', FloatType()),\n",
    "    StructField('Flow Pkts/s', FloatType()),\n",
    "    StructField('Flow IAT Mean', FloatType()),\n",
    "    StructField('Flow IAT Std', FloatType()),\n",
    "    StructField('Flow IAT Max', FloatType()),\n",
    "    StructField('Flow IAT Min', FloatType()),\n",
    "    StructField('Fwd IAT Tot', FloatType()),\n",
    "    StructField('Fwd IAT Mean', FloatType()),\n",
    "    StructField('Fwd IAT Std', FloatType()),\n",
    "    StructField('Fwd IAT Max', FloatType()),\n",
    "    StructField('Fwd IAT Min', FloatType()),\n",
    "    StructField('Bwd IAT Tot', FloatType()),\n",
    "    StructField('Bwd IAT Mean', FloatType()),\n",
    "    StructField('Bwd IAT Std', FloatType()),\n",
    "    StructField('Bwd IAT Max', FloatType()),\n",
    "    StructField('Bwd IAT Min', FloatType()),\n",
    "    StructField('Fwd PSH Flags', IntegerType()),\n",
    "    StructField('Bwd PSH Flags', IntegerType()),\n",
    "    StructField('Fwd URG Flags', IntegerType()),\n",
    "    StructField('Bwd URG Flags', IntegerType()),\n",
    "    StructField('Fwd Header Len', IntegerType()),\n",
    "    StructField('Bwd Header Len', IntegerType()),\n",
    "    StructField('Fwd Pkts/s', FloatType()),\n",
    "    StructField('Bwd Pkts/s', FloatType()),\n",
    "    StructField('Pkt Len Min', FloatType()),\n",
    "    StructField('Pkt Len Max', FloatType()),\n",
    "    StructField('Pkt Len Mean', FloatType()),\n",
    "    StructField('Pkt Len Std', FloatType()),\n",
    "    StructField('Pkt Len Var', FloatType()),\n",
    "    StructField('FIN Flag Cnt', IntegerType()),\n",
    "    StructField('SYN Flag Cnt', IntegerType()),\n",
    "    StructField('RST Flag Cnt', IntegerType()),\n",
    "    StructField('PSH Flag Cnt', IntegerType()),\n",
    "    StructField('ACK Flag Cnt', IntegerType()),\n",
    "    StructField('URG Flag Cnt', IntegerType()),\n",
    "    StructField('CWE Flag Count', IntegerType()),\n",
    "    StructField('ECE Flag Cnt', IntegerType()),\n",
    "    StructField('Down/Up Ratio', FloatType()),\n",
    "    StructField('Pkt Size Avg', FloatType()),\n",
    "    StructField('Fwd Seg Size Avg', FloatType()),\n",
    "    StructField('Bwd Seg Size Avg', FloatType()),\n",
    "    StructField('Fwd Byts/b Avg', IntegerType()),\n",
    "    StructField('Fwd Pkts/b Avg', IntegerType()),\n",
    "    StructField('Fwd Blk Rate Avg', IntegerType()),\n",
    "    StructField('Bwd Byts/b Avg', IntegerType()),\n",
    "    StructField('Bwd Pkts/b Avg', IntegerType()),\n",
    "    StructField('Bwd Blk Rate Avg', IntegerType()),\n",
    "    StructField('Subflow Fwd Pkts', IntegerType()),\n",
    "    StructField('Subflow Fwd Byts', IntegerType()),\n",
    "    StructField('Subflow Bwd Pkts', IntegerType()),\n",
    "    StructField('Subflow Bwd Byts', IntegerType()),\n",
    "    StructField('Init Fwd Win Byts', IntegerType()),\n",
    "    StructField('Init Bwd Win Byts', IntegerType()),\n",
    "    StructField('Fwd Act Data Pkts', IntegerType()),\n",
    "    StructField('Fwd Seg Size Min', IntegerType()),\n",
    "    StructField('Active Mean', FloatType()),\n",
    "    StructField('Active Std', FloatType()),\n",
    "    StructField('Active Max', FloatType()),\n",
    "    StructField('Active Min', FloatType()),\n",
    "    StructField('Idle Mean', FloatType()),\n",
    "    StructField('Idle Std', FloatType()),\n",
    "    StructField('Idle Max', FloatType()),\n",
    "    StructField('Idle Min', FloatType()),\n",
    "    StructField('Label', StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452248d9-033a-4650-ba35-f5beb3189f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefda915-ecb9-44fb-8c10-0a7a1de30f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc89784-a2d8-43b2-b93c-6d66b23a0842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d71844-7b5a-436a-82d4-41b6e7808dfd",
   "metadata": {},
   "source": [
    "# RF model on the entire 6G balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442cada8-2eeb-42f2-b20b-39e2ce89e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"hdfs://172.31.8.146:9000/final_dataset.csv\", schema=schema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9349a590-c346-494b-bfcc-307099d3c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map \"ddos\" to 1 and \"Benign\" to 0 in the label column\n",
    "# This is required by the random forest in PySpark\n",
    "df = df.withColumn(\"Label\", when(col(\"Label\") == \"ddos\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fdadc9-cca0-4a91-a84a-77c39a1b9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_labels = df.select(\"Label\").distinct().collect()\n",
    "\n",
    "# Print the distinct values\n",
    "for row in distinct_labels:\n",
    "    print(row[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2f4b2-ee4f-432f-9821-4552dc45cd67",
   "metadata": {},
   "source": [
    "use the selected features from the feature engineering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b9a0ef-c939-4c4f-9638-6ddfbe086687",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Dst Port',\n",
    "                     'Protocol',\n",
    "                     'Flow Duration',\n",
    "                     'TotLen Fwd Pkts',\n",
    "                     'Fwd Pkt Len Max',\n",
    "                     'Fwd Pkt Len Min',\n",
    "                     'Fwd Pkt Len Std',\n",
    "                     'Bwd Pkt Len Max',\n",
    "                     'Bwd Pkt Len Min',\n",
    "                     'Bwd Pkt Len Mean',\n",
    "                     'Bwd Pkt Len Std',\n",
    "                     'Flow IAT Mean',\n",
    "                     'Flow IAT Std',\n",
    "                     'Flow IAT Max',\n",
    "                     'Flow IAT Min',\n",
    "                     'Fwd IAT Tot',\n",
    "                     'Fwd IAT Mean',\n",
    "                     'Fwd IAT Std',\n",
    "                     'Fwd IAT Max',\n",
    "                     'Fwd IAT Min',\n",
    "                     'Bwd IAT Tot',\n",
    "                     'Bwd IAT Std',\n",
    "                     'Bwd IAT Max',\n",
    "                     'Pkt Len Min',\n",
    "                     'Pkt Len Max',\n",
    "                     'Pkt Len Mean',\n",
    "                     'Pkt Len Std',\n",
    "                     'Pkt Len Var',\n",
    "                     'RST Flag Cnt',\n",
    "                     'ECE Flag Cnt',\n",
    "                     'Down/Up Ratio',\n",
    "                     'Bwd Seg Size Avg',\n",
    "                     'Subflow Fwd Byts',\n",
    "                     'Init Fwd Win Byts',\n",
    "                     'Fwd Act Data Pkts',\n",
    "                     'Idle Mean',\n",
    "                     'Idle Max',\n",
    "                     'Idle Min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dea303c-e22d-4377-ac92-1e3acbd81be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [col for col in df.columns if col in selected_features]\n",
    "\n",
    "# Select features\n",
    "assembler = VectorAssembler(inputCols=selected_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536de46-b69a-4b41-b05e-aaa217501de7",
   "metadata": {},
   "source": [
    "### Perform data preprocessing using scaler\n",
    "Feature scaling (also known as data normalization or standardization) is a preprocessing step that transforms the features (columns) of a dataset to have similar scales or ranges.\n",
    "\n",
    "The purpose of feature scaling here is to ensure that all features contribute equally to our model training process, preventing features with larger scales from dominating those with smaller scales. It also helps the algorithms converge faster and may improve the performance of certain machine learning algorithms, particularly those that rely on distance metrics or gradient descent optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc8c485-fad4-4109-a8e9-28994bad5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f31b1c-7a72-45de-b33f-b00d0d4ca79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16550644-3659-405d-af9f-62b55bda38d2",
   "metadata": {},
   "source": [
    "### Use PCA for feature selection to reduce the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14b07a8-e3b2-4b4d-8155-cc3eb21c59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 10 principal components\n",
    "pca = PCA(k=10, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32a0fc-3294-4f32-8cf1-9cdda0058c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42313a9c-47c8-43b5-b424-b7d3fa614e8d",
   "metadata": {},
   "source": [
    "### We adopt the hyperparameter combination of the one we got from the previous tunning processing on the small-scale dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aedb064-c8a5-488d-9ace-971be145f22e",
   "metadata": {},
   "source": [
    "## Results of using the folloing hyperparameter values\n",
    "- num_trees = 10\n",
    "- max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20b9e10f-30df-46e7-8abc-cb9cd6d5e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fixed values for numTrees and maxDepth\n",
    "num_trees = 10\n",
    "max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc3bcb-6d23-4117-8a65-9b09ebb34143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461ea686-d5a5-4246-b82e-f71bcfa1117f",
   "metadata": {},
   "source": [
    "### Define a new Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ad9396c-c370-402d-8e92-4f7cb9c30819",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"Label\", featuresCol=\"pcaFeatures\", numTrees=num_trees, maxDepth=max_depth)\n",
    "pipeline = Pipeline(stages=[assembler, scaler, pca, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8d60d-4610-494a-9482-c05571ccef74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078cba8d-4747-41d4-983c-ebf6909002ad",
   "metadata": {},
   "source": [
    "### Try k-fold cross validation (10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd3482d6-b580-4d47-9b72-470731db2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ROC index for evaluation\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Label\", metricName=\"areaUnderROC\")\n",
    "# we do not need grid search this time, but the empty parameter is required by the CrossValidator\n",
    "params_grid = ParamGridBuilder().build()\n",
    "# 10-fold cross-validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=params_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da851d7-da91-4ab6-801c-1c32138024a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================================> (50 + 1) / 51]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_labels = df.select(\"Label\").distinct().collect()\n",
    "\n",
    "# Print the distinct values\n",
    "for row in distinct_labels:\n",
    "    print(row[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4282aae-e72e-4b1b-bb40-9e848a066978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "(df_train, df_test) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842f58a-812e-4820-9ffe-e19c9cf821aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c78564d-2946-438a-867b-2bbe4f708461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 s, sys: 633 ms, total: 4.03 s\n",
      "Wall time: 36min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867da16-b87b-4dd7-a032-58e1750d46d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cc4d4c8-6baa-4578-aa7d-dbab7c68ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 3.47 ms, total: 19.1 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions on training set\n",
    "predictions_train = cvModel.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a53dc75-4a07-4a53-9a80-5f6934fd47c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 ms, sys: 4.14 ms, total: 17 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions on validation set\n",
    "predictions_test = cvModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc14a8b-c8ae-4b8c-b545-ff0f2d0ccf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35db42-6c4d-4a7f-a386-440b37928b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb46eb-8678-46c3-aa81-37bd539146c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03752520-7179-4515-913d-469b843bbe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.994551181641148"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance on the training set\n",
    "roc_train = evaluator.evaluate(predictions_train)\n",
    "roc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f8fe9de-0f37-4b94-9b57-c8f06b7ff41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.994633510548535"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance on the validation set\n",
    "roc_test = evaluator.evaluate(predictions_test)\n",
    "roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094565c-c408-417e-931b-c356f529381a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "783b506f-5a34-47fc-b301-edfbc1f21985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 459:====================================================>  (49 + 2) / 51]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DDoS Detection Performance on the testing set ===\n",
      "Accuracy:  0.9745150917548979\n",
      "Precision:  0.9811725607039579\n",
      "Recall:  0.9670248576003914\n",
      "F1 Score:  0.9745118152367145\n",
      "ROC:  0.994633510548535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# more evaluations\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define a multiclass classification evaluator\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(labelCol=\"Label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"precisionByLabel\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"recallByLabel\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"=== DDoS Detection Performance on the testing set ===\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "print(\"ROC: \", roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3307ee7-ac5f-4a11-829f-e7ce57980c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 467:=====================================================> (50 + 1) / 51]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DDoS Detection Performance on the training set ===\n",
      "Accuracy:  0.9746053844175513\n",
      "Precision:  0.9813680295828863\n",
      "Recall:  0.9669439940843246\n",
      "F1 Score:  0.9746018040369947\n",
      "ROC:  0.994551181641148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"precisionByLabel\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"recallByLabel\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"=== DDoS Detection Performance on the training set ===\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(\"Precision: \", precision_train)\n",
    "print(\"Recall: \", recall_train)\n",
    "print(\"F1 Score: \", f1_score_train)\n",
    "print(\"ROC: \", roc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c95a10-623a-49da-b211-555377fce411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7123700-097c-44cd-8da8-4faf685d8487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02120a85-e950-4cfe-a9f0-9349d7bf8118",
   "metadata": {},
   "source": [
    "## Results of using the folloing hyperparameter values\n",
    "- num_trees = 30\n",
    "- max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee1e783-7879-4d4b-b8d6-f302541947af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fixed values for numTrees and maxDepth\n",
    "num_trees = 10\n",
    "max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7e9b56-5d5f-4cd3-912b-c90be64d8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"Label\", featuresCol=\"pcaFeatures\", numTrees=num_trees, maxDepth=max_depth)\n",
    "pipeline = Pipeline(stages=[assembler, scaler, pca, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad14315-9ba7-40f9-b8aa-5698ddb8ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ROC index for evaluation\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Label\", metricName=\"areaUnderROC\")\n",
    "# we do not need grid search this time, but the empty parameter is required by the CrossValidator\n",
    "params_grid = ParamGridBuilder().build()\n",
    "# 10-fold cross-validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=params_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58c54862-2e27-4ff2-a0db-8193d73ee6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "(df_train, df_test) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea73f15-71b8-4cd8-8602-b508225acc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/29 23:06:44 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/29 23:09:31 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/04/29 23:09:31 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.02 s, sys: 905 ms, total: 4.93 s\n",
      "Wall time: 40min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = crossval.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75939e38-f377-4d0e-b014-b534b6e78e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 0 ns, total: 19.6 ms\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions on training set\n",
    "predictions_train = cvModel.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e10eee32-e54c-4065-a8ff-0ac8dccc2bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 1.85 ms, total: 17.9 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions on validation set\n",
    "predictions_test = cvModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077edead-bc7e-4480-8084-01ded82b5a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9951357269560265"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance on the training set\n",
    "roc_train = evaluator.evaluate(predictions_train)\n",
    "roc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a742b7-4b91-4656-95df-1cbf5ef9b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9952070755959271"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the performance on the validation set\n",
    "roc_test = evaluator.evaluate(predictions_test)\n",
    "roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74203688-fe06-41b2-a433-ad0fea5df292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 438:=====================================================> (50 + 1) / 51]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DDoS Detection Performance on the testing set ===\n",
      "Accuracy:  0.9753030659027357\n",
      "Precision:  0.9780745875334589\n",
      "Recall:  0.9717805443255119\n",
      "F1 Score:  0.9753018587169614\n",
      "ROC:  0.9952070755959271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# more evaluations\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define a multiclass classification evaluator\n",
    "multiclass_evaluator = MulticlassClassificationEvaluator(labelCol=\"Label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"precisionByLabel\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"recallByLabel\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = multiclass_evaluator.evaluate(predictions_test, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"=== DDoS Detection Performance on the testing set ===\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "print(\"ROC: \", roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46285379-b019-4f87-a741-90617720b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 446:=====================================================> (50 + 1) / 51]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DDoS Detection Performance on the training set ===\n",
      "Accuracy:  0.9752463755175839\n",
      "Precision:  0.9778728577190282\n",
      "Recall:  0.9719040389087361\n",
      "F1 Score:  0.9752452841984975\n",
      "ROC:  0.9951357269560265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "# Calculate precision\n",
    "precision_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"precisionByLabel\"})\n",
    "\n",
    "# Calculate recall\n",
    "recall_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"recallByLabel\"})\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score_train = multiclass_evaluator.evaluate(predictions_train, {multiclass_evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"=== DDoS Detection Performance on the training set ===\")\n",
    "print(\"Accuracy: \", accuracy_train)\n",
    "print(\"Precision: \", precision_train)\n",
    "print(\"Recall: \", recall_train)\n",
    "print(\"F1 Score: \", f1_score_train)\n",
    "print(\"ROC: \", roc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b9e7a-29ff-4c97-965a-6c95c8ec6b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c63ca5-0e88-4e93-9c3a-6fd3ca686a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
